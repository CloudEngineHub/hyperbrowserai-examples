{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Building a Documentation Q&A Agent with Hyperbrowser and o3-mini\n",
                "\n",
                "In this coookbook, we'll build a powerful documentation Q&A agent that can answer questions about any company's products by automatically scraping their documentation. This approach combines:\n",
                "\n",
                "- **Hyperbrowser** for reading web pages in LLM-friendly Markdown format\n",
                "- **OpenAI's o3-mini reasoning model** for natural language understanding and response generation\n",
                "- **Tool-calling** to create an agent that can browse the web autonomously\n",
                "\n",
                "By the end of this cookbook, you'll have a reusable agent that can be configured for any company's documentation site!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Prerequisites\n",
                "\n",
                "Before starting, make sure you have:\n",
                "\n",
                "1. A Hyperbrowser API key (sign up at [hyperbrowser.ai](https://hyperbrowser.ai) if you don't have one, it's free)\n",
                "2. An OpenAI API key\n",
                "3. Python 3.9+ installed\n",
                "\n",
                "Both API keys should be stored in a `.env` file in the same directory as this notebook with the following format:\n",
                "\n",
                "```shell\n",
                "HYPERBROWSER_API_KEY=your_hyperbrowser_key_here\n",
                "OPENAI_API_KEY=your_openai_key_here\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Set up imports and load environment variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import asyncio\n",
                "import json\n",
                "import os\n",
                "\n",
                "from dotenv import load_dotenv\n",
                "from hyperbrowser import AsyncHyperbrowser\n",
                "from hyperbrowser.tools import WebsiteScrapeTool\n",
                "from openai import AsyncOpenAI\n",
                "from openai.types.chat import (\n",
                "    ChatCompletionMessageParam,\n",
                "    ChatCompletionMessageToolCall,\n",
                "    ChatCompletionToolMessageParam,\n",
                ")\n",
                "\n",
                "load_dotenv()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Initialize clients"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "hb = AsyncHyperbrowser(api_key=os.getenv(\"HYPERBROWSER_API_KEY\"))\n",
                "oai = AsyncOpenAI()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Create helper functions for tool handling\n",
                "\n",
                "Next, we'll define a function to handle tool calls from the LLM. This function will accept a `ChatCompletionMessageToolCall` object and return a `ChatCompletionToolMessageParam` object. \n",
                "\n",
                "This function currently only works with the `WebsiteScrapeTool` but you can change this code to work with your own custom tools pretty easily."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "async def handle_tool_call(\n",
                "    tc: ChatCompletionMessageToolCall,\n",
                ") -> ChatCompletionToolMessageParam:\n",
                "    print(f\"Handling tool call: {tc.function.name}\")\n",
                "\n",
                "    try:\n",
                "        if (\n",
                "            tc.function.name != WebsiteScrapeTool.openai_tool_definition[\"function\"][\"name\"]\n",
                "        ):\n",
                "            raise ValueError(f\"Tool not found: {tc.function.name}\")\n",
                "\n",
                "        args = json.loads(tc.function.arguments)\n",
                "        content = await WebsiteScrapeTool.async_runnable(hb=hb, params=args)\n",
                "\n",
                "        return {\"role\": \"tool\", \"tool_call_id\": tc.id, \"content\": content}\n",
                "\n",
                "    except Exception as e:\n",
                "        err_msg = f\"Error handling tool call: {e}\"\n",
                "        print(err_msg)\n",
                "        return {\n",
                "            \"role\": \"tool\",\n",
                "            \"tool_call_id\": tc.id,\n",
                "            \"content\": err_msg,\n",
                "            \"is_error\": True,\n",
                "        }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Implement the agent loop\n",
                "\n",
                "Now we'll create the main agent loop that orchestrates the conversation between the user, the LLM, and the tools. This function:\n",
                "\n",
                "1. Takes a list of messages (including system prompt and user query)\n",
                "2. Sends them to the OpenAI API\n",
                "3. Processes any tool calls that the LLM makes\n",
                "4. Continues the conversation until the LLM provides a final answer\n",
                "\n",
                "This is the core of our agent's functionality."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "async def agent_loop(messages: list[ChatCompletionMessageParam]) -> str:\n",
                "    while True:\n",
                "        response = await oai.chat.completions.create(\n",
                "            messages=messages,\n",
                "            model=\"gpt-4o\",\n",
                "            tools=[\n",
                "                WebsiteScrapeTool.openai_tool_definition,\n",
                "            ],\n",
                "            max_completion_tokens=8000,\n",
                "        )\n",
                "\n",
                "        choice = response.choices[0]\n",
                "\n",
                "        # Append response to messages\n",
                "        messages.append(choice.message)\n",
                "\n",
                "        # Handle tool calls\n",
                "        if choice.finish_reason == \"tool_calls\":\n",
                "            tool_result_messages = await asyncio.gather(\n",
                "                *[handle_tool_call(tc) for tc in choice.message.tool_calls]\n",
                "            )\n",
                "            messages.extend(tool_result_messages)\n",
                "\n",
                "        elif choice.finish_reason == \"stop\":\n",
                "            return choice.message.content\n",
                "\n",
                "        else:\n",
                "            raise ValueError(f\"Unhandled finish reason: {choice.finish_reason}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Design the system prompt\n",
                "\n",
                "The system prompt is crucial for guiding the LLM's behavior. Our prompt:\n",
                "\n",
                "1. Establishes the LLM as an expert on a specific company's products\n",
                "2. Explains the available tools and how to use them\n",
                "3. Provides a structured approach for answering questions\n",
                "4. Sets guidelines for handling different types of queries\n",
                "\n",
                "This prompt uses placeholders that will be filled in when we create a specific agent instance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "SYSTEM_PROMPT = \"\"\"\n",
                "You are an expert on {company_name}'s products and documentation. You have access to a 'scrape_webpage' tool \\\n",
                "that allows you to read web pages by providing a URL. \n",
                "\n",
                "This is {company_name}'s documentation site's LLMs.txt URL: {llms_txt_url}.\n",
                "The llms.txt file contains links to all {company_name}'s product documentation pages.\n",
                "\n",
                "When answering questions:\n",
                "1. If the question is about {company_name}'s products, use the 'scrape_webpage' tool to get the contents of \\\n",
                "the llms.txt file\n",
                "2. If any of the URLs in the llms.txt file are relevant to the question, use the 'scrape_webpage' tool to \\\n",
                "get the contents of the page\n",
                "3. Provide detailed answers with citations to the specific documentation pages\n",
                "4. If you can't find the answer in the docs, respond with: \"I don't know the answer to that. I couldn't find \\\n",
                "anything relevant to it in the docs, please try contacting the {company_name} team.\"\n",
                "5. If the question is unrelated to {company_name}'s products, respond with: \"I can only answer questions \\\n",
                "about {company_name}'s products\"\n",
                "\n",
                "Always cite your sources by including the relevant documentation URLs. Respond with your chain of thought \\\n",
                "and the final answer to the user.\n",
                "\"\"\".strip()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Create a factory function for generating Q&A agents\n",
                "\n",
                "Now we'll create a factory function that generates a specialized Q&A agent for any company's documentation. This function:\n",
                "\n",
                "1. Takes a company name and documentation URL as input\n",
                "2. Formats the system prompt with these values\n",
                "3. Returns a function that can answer questions about that company's products\n",
                "\n",
                "This approach makes our solution reusable for different companies and documentation sites."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_support_agent(company_name: str, docs_url: str) -> str:\n",
                "    # Popular documentation providers like Gitbook, Mintlify etc automatically generate a llms.txt file\n",
                "    # for documentation sites hosted on their platforms.\n",
                "    if docs_url.startswith(\"http://\") or docs_url.startswith(\"https://\"):\n",
                "        llms_txt_url = f\"{docs_url}/llms.txt\"\n",
                "    else:\n",
                "        llms_txt_url = f\"https://{docs_url}/llms.txt\"\n",
                "\n",
                "    sysprompt = SYSTEM_PROMPT.format(\n",
                "        company_name=company_name,\n",
                "        llms_txt_url=llms_txt_url,\n",
                "    )\n",
                "\n",
                "    async def qna(question: str) -> str:\n",
                "        return await agent_loop([\n",
                "            {\"role\": \"system\", \"content\": sysprompt},\n",
                "            {\"role\": \"user\", \"content\": question},\n",
                "        ])\n",
                "\n",
                "    return qna"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 7: Test the agent with a real question\n",
                "\n",
                "Let's test our agent by creating an instance for Hyperbrowser's documentation and asking it a question. This will demonstrate the full workflow:\n",
                "\n",
                "1. The agent receives a question about CAPTCHAs in Hyperbrowser\n",
                "2. It uses the `scrape_webpage` tool to access the documentation\n",
                "3. It processes the information and formulates a detailed answer\n",
                "4. It returns the answer with citations to the relevant documentation\n",
                "\n",
                "You'll see the tool calls being made in real-time as the agent works through the question."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Handling tool call: scrape_webpage\n",
                        "Handling tool call: scrape_webpage\n",
                        "Handling tool call: scrape_webpage\n",
                        "\n",
                        "\n",
                        " ==================== Answer ==================== \n",
                        "\n",
                        "\n",
                        "To address the issue of being blocked by CAPTCHAs when using Hyperbrowser's Python SDK, you can leverage Hyperbrowser's CAPTCHA solving feature. Here’s a summary of how to integrate CAPTCHA solving into your scraping tasks:\n",
                        "\n",
                        "1. **CAPTCHA Solving Feature**: Hyperbrowser provides an integrated CAPTCHA solver that allows you to scrape websites without being blocked. However, please note that to use this feature, you must be on a paid plan.\n",
                        "\n",
                        "2. **Setup for CAPTCHA Solving**: When creating a Hyperbrowser session, enable CAPTCHA solving by setting the `solveCaptchas` parameter to `true`. This can be done via the SDK when creating a new session:\n",
                        "\n",
                        "   ```python\n",
                        "   from hyperbrowser import AsyncHyperbrowser\n",
                        "   import os\n",
                        "   from dotenv import load_dotenv\n",
                        "   import asyncio\n",
                        "\n",
                        "   load_dotenv()\n",
                        "   client = AsyncHyperbrowser(api_key=os.getenv(\"HYPERBROWSER_API_KEY\"))\n",
                        "\n",
                        "   async def main():\n",
                        "       session = await client.sessions.create(solveCaptchas=True)\n",
                        "       # Your scraping code here\n",
                        "       await client.sessions.stop(session.id)\n",
                        "\n",
                        "   asyncio.get_event_loop().run_until_complete(main())\n",
                        "   ```\n",
                        "\n",
                        "3. **Session Creation**: The session configured with CAPTCHA solving will automatically handle CAPTCHAs encountered during navigation or data extraction processes.\n",
                        "\n",
                        "4. **Running the Scraper**: Implement the rest of your code to perform scraping. The CAPTCHA solving process runs in the background, solving CAPTCHAs and continuing page loads without your script being explicitly aware of CAPTCHA handling.\n",
                        "\n",
                        "For full details and more code examples, you can refer to the official documentation on [CAPTCHA Solving with Hyperbrowser](https://docs.hyperbrowser.ai/guides/captcha-solving) and the [Python SDK](https://docs.hyperbrowser.ai/reference/sdks/python).\n",
                        "\n",
                        "By utilizing these features, you should be able to bypass CAPTCHA challenges and perform your web scraping tasks more smoothly.\n"
                    ]
                }
            ],
            "source": [
                "hyperbrowser_qna = make_support_agent(\"Hyperbrowser\", \"https://docs.hyperbrowser.ai\")\n",
                "question = \"I'm getting blocked by CAPTCHAs when scraping a website with hyperbrowser. How do I fix it? I'm using the python sdk\"\n",
                "\n",
                "answer = await hyperbrowser_qna(question)\n",
                "\n",
                "print(\"\\n\\n\", \"=\"*20, \"Answer\", \"=\"*20, \"\\n\\n\")\n",
                "print(answer)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 8: Try it with your own questions\n",
                "\n",
                "Now that you've seen how the agent works, you can try asking your own questions about Hyperbrowser or create agents for other companies' documentation. Simply modify the code below with your question or create a new agent for a different company.\n",
                "\n",
                "```python\n",
                "# Example: Create an agent for a different company\n",
                "# langchain_qna = make_support_agent(\"Anthropic\", \"https://docs.anthropic.com\")\n",
                "# question = \"How do I build a computer use agent?\"\n",
                "# answer = await langchain_qna(question)\n",
                "# print(answer)\n",
                "```\n",
                "\n",
                "Feel free to experiment with different questions and documentation sites!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "In this cookbook, we built a powerful documentation Q&A agent using Hyperbrowser and OpenAI. This agent can:\n",
                "\n",
                "1. Autonomously navigate documentation websites\n",
                "2. Extract relevant information based on user questions\n",
                "3. Provide detailed, cited answers from the documentation\n",
                "4. Be easily adapted for different companies and products\n",
                "5. Always stay up to date with the latest documentation because it scrapes the llms.txt file on every run\n",
                "\n",
                "\n",
                "This pattern can be extended to create more sophisticated agents that can interact with multiple websites, use additional tools, or be integrated into larger applications.\n",
                "\n",
                "### Next Steps\n",
                "\n",
                "To take this further, you might consider:\n",
                "- Adding memory to the agent to remember previous questions and answers\n",
                "- Implementing caching to improve performance\n",
                "- Creating a web interface for easier interaction\n",
                "- Adding more tools for different types of web interactions\n",
                "- Making swarms of such agents to answer questions about integrating multiple products together\n",
                "\n",
                "Happy building!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Relevant Links\n",
                "- [Hyperbrowser](https://hyperbrowser.ai)\n",
                "- [Hyperbrowser Documentation](https://docs.hyperbrowser.ai)\n",
                "- [OpenAI Docs](https://platform.openai.com/docs/introduction)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
