{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Building a Smart Shopping Assistant with Hyperbrowser and GPT-4o\n",
                "\n",
                "In this cookbook, we'll build an intelligent shopping assistant that can search for products, extract pricing information, and provide personalized recommendations based on user preferences. Our assistant will:\n",
                "\n",
                "1. Search for products on Google Shopping\n",
                "2. Extract detailed product information including prices, brands, and categories\n",
                "3. Filter results based on user preferences (price range, gender, size, etc.)\n",
                "4. Provide tailored shopping recommendations\n",
                "\n",
                "We'll use these tools to build our assistant:\n",
                "- **[Hyperbrowser](https://hyperbrowser.ai)** for web scraping and data extraction from shopping sites\n",
                "- **OpenAI's GPT-4o** for intelligent product analysis and personalized recommendations\n",
                "\n",
                "By the end of this cookbook, you'll have a versatile shopping assistant that can help you find the best products matching your specific requirements!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Prerequisites\n",
                "\n",
                "To follow along you'll need the following:\n",
                "\n",
                "1. A Hyperbrowser API key (sign up at [hyperbrowser.ai](https://hyperbrowser.ai) if you don't have one, it's free)\n",
                "2. An OpenAI API key (sign up at [openai.com](https://openai.com) if you don't have one, it's free)\n",
                "\n",
                "Both API keys should be stored in a `.env` file in the same directory as this notebook with the following format:\n",
                "\n",
                "```\n",
                "HYPERBROWSER_API_KEY=your_hyperbrowser_key_here\n",
                "OPENAI_API_KEY=your_openai_key_here\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Set up imports and load environment variables\n",
                "\n",
                "First, we'll import all the necessary libraries and initialize our environment. This includes:\n",
                "- Hyperbrowser for web scraping and data extraction\n",
                "- OpenAI for AI-powered analysis \n",
                "- Pydantic for data validation and modeling\n",
                "- Other utility libraries for handling async operations and formatting"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import asyncio\n",
                "import json\n",
                "import os\n",
                "\n",
                "from dotenv import load_dotenv\n",
                "from hyperbrowser import AsyncHyperbrowser\n",
                "from hyperbrowser.tools import WebsiteExtractTool,WebsiteScrapeTool\n",
                "from hyperbrowser.models.session import CreateSessionParams,CreateSessionProfile\n",
                "from hyperbrowser.models.extract import StartExtractJobParams\n",
                "from hyperbrowser.models.scrape import StartBatchScrapeJobParams,StartScrapeJobParams,ScrapeOptions\n",
                "from openai import AsyncOpenAI\n",
                "from openai.types.chat import (\n",
                "    ChatCompletionMessageParam,\n",
                "    ChatCompletionSystemMessageParam,\n",
                "    ChatCompletionUserMessageParam,\n",
                "    ChatCompletionMessageToolCall,\n",
                "    ChatCompletionToolMessageParam,\n",
                ")\n",
                "from typing import List,Literal\n",
                "from pydantic import BaseModel\n",
                "from IPython.display import Markdown, display\n",
                "\n",
                "load_dotenv()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Initialize API clients\n",
                "\n",
                "Next, we'll create instances of the Hyperbrowser and OpenAI clients using our API keys. These clients will be responsible for web data extraction and AI-powered product analysis respectively."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "hb = AsyncHyperbrowser(api_key=os.getenv(\"HYPERBROWSER_API_KEY\"))\n",
                "llm = AsyncOpenAI()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Define data models and scraping functionality\n",
                "\n",
                "Now we'll define our data models and functions to scrape shopping results. The main components are:\n",
                "\n",
                "1. `PriceExtractSchema` - Models a single product with details like price, name, brand, and category\n",
                "2. `PriceExtractSchemaList` - A container for multiple product listings\n",
                "3. `scrape_shopping_results()` - Scrapes Google Shopping for a given search query\n",
                "4. `extract_product_data()` - Uses GPT-4o to extract structured product data from raw scraped content\n",
                "\n",
                "The scraping function uses Hyperbrowser's advanced features like tag filtering to target only the relevant shopping elements on the page."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import Optional\n",
                "import urllib.parse\n",
                "\n",
                "class PriceExtractSchema(BaseModel):\n",
                "    current_price:float\n",
                "    actual_price:Optional[float]\n",
                "    product_name:str\n",
                "    product_category:Literal[\"women\", \"men\", \"children\"]\n",
                "    product_brand:str\n",
                "    shop:str\n",
                "    size:Optional[str]\n",
                "    source:Literal[\"google\", \"bing\"]\n",
                "\n",
                "class PriceExtractSchemaList(BaseModel):\n",
                "    products:List[PriceExtractSchema]\n",
                "\n",
                "async def scrape_shopping_results(query: str):\n",
                "    # Configure extract parameters\n",
                "    scrape_params = StartScrapeJobParams(\n",
                "        url=f\"https://www.google.com/search?q={urllib.parse.quote_plus(query)}&tbm=shop\",\n",
                "        session_options=CreateSessionParams(\n",
                "         \n",
                "        ),\n",
                "        scrape_options=ScrapeOptions(\n",
                "            formats=[\"markdown\"],\n",
                "            # Filter out the shopping card elements only\n",
                "            exclude_tags=[\"img\"],\n",
                "            include_tags=[\"div[jsname='Nhy0ad']\"],\n",
                "            only_main_content=True\n",
                "        )\n",
                "    )\n",
                "    scrape_results = await hb.scrape.start_and_wait(scrape_params)\n",
                "    if (scrape_results.error):\n",
                "        raise Exception(scrape_results.error)\n",
                "    elif (scrape_results.data is None or scrape_results.data.markdown is None):\n",
                "        raise Exception(\"No data found\")\n",
                "    \n",
                "    return scrape_results.data.markdown\n",
                "\n",
                "async def extract_product_data(markdown_content: str) -> PriceExtractSchemaList:\n",
                "    messages: List[ChatCompletionMessageParam] = [\n",
                "        {\n",
                "            \"role\": \"system\",\n",
                "            \"content\": \"\"\"You are a helpful assistant that can search for products on Google Shopping and return the results in a structured format.You will be provided with the markdown content of the page, and have to extract structured data from it regarding the product.\"\"\"\n",
                "        },{\n",
                "            \"role\":\"user\",\n",
                "            \"content\":f\"\"\"Here is the markdown content of the page:\n",
                "            {markdown_content}\n",
                "            \"\"\"\n",
                "        }\n",
                "    ]\n",
                "\n",
                "    structured_extraction = await llm.beta.chat.completions.parse(messages=messages,model=\"gpt-4o-mini\",response_format=PriceExtractSchemaList,max_tokens=10000)\n",
                "    if (structured_extraction.choices[0].message.parsed is None):\n",
                "        raise Exception(\"No structured data found\")\n",
                "\n",
                "    return structured_extraction.choices[0].message.parsed"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Implement product filtering and recommendation\n",
                "\n",
                "Once we have the raw product data, we need to filter it according to user preferences and provide personalized recommendations. The `analyze_shopping_results()` function:\n",
                "\n",
                "1. Takes the list of extracted products and user parameters (price range, gender, size, etc.)\n",
                "2. Uses GPT-4o-mini with a specialized system prompt to analyze the products\n",
                "3. Filters the results to match user preferences\n",
                "4. Returns a structured list of recommended products\n",
                "\n",
                "This approach combines structured data filtering with AI-powered analysis to provide tailored recommendations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "async def analyze_shopping_results(results: PriceExtractSchemaList,**kwargs):\n",
                "    messages: List[ChatCompletionMessageParam] = [\n",
                "        {\n",
                "            \"role\": \"system\",\n",
                "            \"content\": \"\"\"You are a helpful shopping assistant that analyzes product listings and provides insights about pricing and options.Please analyze them and provide insights about:\n",
                "\n",
                "            The user will also provide parameters like price range, product category, brand, size, etc. Filter the results based on the parameters and provide the best options.\n",
                "            - Price ranges and best deals\n",
                "            - Product categories and brands represented\n",
                "            - Size availability where applicable\n",
                "            - Comparison between Google and Bing results\"\"\"\n",
                "        },\n",
                "        {\n",
                "            \"role\": \"user\", \n",
                "            \"content\": f\"\"\"Here are some shopping results. \n",
                "\n",
                "            User Parameters:\n",
                "            {\"\\n\".join([f\"{key} should be {kwargs[key]}\" for key in (kwargs).keys()])}\n",
                "            \n",
                "            Results:\n",
                "            {results.model_dump_json(indent=2)}\n",
                "            \"\"\"\n",
                "        }\n",
                "    ]\n",
                "    \n",
                "    response = await llm.beta.chat.completions.parse(\n",
                "        model=\"gpt-4o-mini\",\n",
                "        messages=messages,\n",
                "        temperature=0.7,\n",
                "        response_format=PriceExtractSchemaList\n",
                "    )\n",
                "    \n",
                "    return response.choices[0].message.parsed\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Define search parameters\n",
                "\n",
                "Now we'll set up our search query and user parameters. This includes:\n",
                "\n",
                "1. The product we're searching for (\"New Balance 574\" in this example)\n",
                "2. User preferences like minimum price, gender, and size\n",
                "3. A maximum length limit for the scraped content to prevent processing issues\n",
                "\n",
                "These parameters will guide our shopping assistant in finding the most relevant products."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "query = \"New Balance 574\"\n",
                "\n",
                "parameters = {\n",
                "    \"Min price\": 50,\n",
                "    \"Gender\":\"male\",\n",
                "    \"Size\":\"10 or close to it\"\n",
                "}\n",
                "\n",
                "MAX_MARKDOWN_LENGTH = 10000"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Scrape shopping results\n",
                "\n",
                "Let's execute our scraping function to get product data from Google Shopping. This step:\n",
                "\n",
                "1. Sends a search query to Google Shopping\n",
                "2. Uses Hyperbrowser to scrape the search results page\n",
                "3. Returns the raw markdown content containing product listings\n",
                "\n",
                "This is the data collection phase of our shopping assistant."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "markdown_content = await scrape_shopping_results(query)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 7: Extract and process product information\n",
                "\n",
                "Now we'll process the raw markdown content to extract structured product information. This step:\n",
                "\n",
                "1. Limits the content length if necessary to prevent processing issues\n",
                "2. Uses our extraction function with GPT-4o-mini to parse the content\n",
                "3. Returns a structured list of products with detailed information\n",
                "\n",
                "The result will be a comprehensive set of product listings in a structured format ready for analysis and filtering."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "if (len(markdown_content) > MAX_MARKDOWN_LENGTH):\n",
                "    markdown_content = markdown_content[:MAX_MARKDOWN_LENGTH]\n",
                "shopping_results = await extract_product_data(markdown_content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 8: Generate personalized recommendations\n",
                "\n",
                "Finally, we'll analyze the product data and generate personalized recommendations based on the user's parameters. This step:\n",
                "\n",
                "1. Takes the extracted product data and user parameters \n",
                "2. Uses our `analyze_shopping_results()` function to filter and analyze the products\n",
                "3. Returns a filtered list of recommended products that match the user's preferences\n",
                "\n",
                "The result will be a tailored set of recommendations that consider factors like gender, price range, and size preferences."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "sorted_results = await analyze_shopping_results(shopping_results,**parameters)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Recommended Products:\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "1. New Balance Men's 574\n",
                        "   Discounted Price: $89.99\n",
                        "   Brand: New Balance\n",
                        "   Category: men\n",
                        "   Shop: New Balance & more\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "2. New Balance Numeric Men's 574 Vulc\n",
                        "   Discounted Price: $89.99\n",
                        "   Brand: New Balance\n",
                        "   Category: men\n",
                        "   Shop: New Balance & more\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "3. New Balance Men's Golf 574 Greens v2 Shoes\n",
                        "   Discounted Price: $99.99\n",
                        "   Brand: New Balance\n",
                        "   Category: men\n",
                        "   Shop: New Balance & more\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "4. New Balance Men's 1906A\n",
                        "   Discounted Price: $169.99\n",
                        "   Brand: New Balance\n",
                        "   Category: men\n",
                        "   Shop: New Balance & more\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "5. Men's New Balance 574\n",
                        "   Discounted Price: $90.00\n",
                        "   Brand: New Balance\n",
                        "   Category: men\n",
                        "   Shop: Foot Locker & more\n",
                        "--------------------------------------------------\n",
                        "\n",
                        "6. New Balance 574 Men's Shoes\n",
                        "   Discounted Price: $65.00\n",
                        "   Actual Price: $90.00\n",
                        "   Brand: New Balance\n",
                        "   Category: men\n",
                        "   Shop: Finish Line & more\n",
                        "--------------------------------------------------\n"
                    ]
                }
            ],
            "source": [
                "if sorted_results:\n",
                "    print(\"\\nRecommended Products:\")\n",
                "    print(\"-\" * 50)\n",
                "    for i, product in enumerate(sorted_results.products, 1):\n",
                "        print(f\"\\n{i}. {product.product_name}\")\n",
                "        print(f\"   Discounted Price: ${product.current_price:.2f}\")\n",
                "        if product.actual_price:\n",
                "            print(f\"   Actual Price: ${product.actual_price:.2f}\")\n",
                "        print(f\"   Brand: {product.product_brand}\")\n",
                "        print(f\"   Category: {product.product_category}\")\n",
                "        if product.size:\n",
                "            print(f\"   Size: {product.size}\")\n",
                "        if product.shop:\n",
                "            print(f\"   Shop: {product.shop}\")\n",
                "        print(\"-\" * 50)\n",
                "else:\n",
                "    print(\"No products found matching the parameters.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "In this cookbook, we built a powerful shopping assistant using Hyperbrowser and OpenAI's GPT-4o. Our assistant can:\n",
                "\n",
                "1. Search for products on Google Shopping using specific queries\n",
                "2. Extract detailed product information including prices, brands, and categories\n",
                "3. Filter results based on user preferences like price range, gender, and size\n",
                "4. Provide personalized product recommendations\n",
                "\n",
                "This approach combines web scraping, structured data extraction, and AI-powered analysis to create a versatile shopping assistant that can help users find the best products matching their specific requirements.\n",
                "\n",
                "### Next Steps\n",
                "\n",
                "To take this further, you might consider:\n",
                "- Adding support for more shopping platforms (Amazon, Walmart, etc.)\n",
                "- Implementing price tracking and deal alerts\n",
                "- Creating a web interface for easier interaction\n",
                "- Adding product review analysis\n",
                "- Integrating with shopping APIs for more reliable data\n",
                "\n",
                "Happy shopping!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Relevant Links\n",
                "- [Hyperbrowser](https://hyperbrowser.ai)\n",
                "- [Hyperbrowser Documentation](https://docs.hyperbrowser.ai)\n",
                "- [OpenAI API Documentation](https://platform.openai.com/docs/introduction)\n",
                "- [Pydantic Documentation](https://docs.pydantic.dev/)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
